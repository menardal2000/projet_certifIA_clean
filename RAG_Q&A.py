import os
import time
import torch
import httpx
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
from mistralai import Mistral
import datauri  
from mistralai.models import OCRResponse
from transformers import AutoTokenizer, AutoModel
from huggingface_hub import login
from langchain.schema import Document as LangDocument
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_mistralai import MistralAIEmbeddings, ChatMistralAI
from docx import Document as WordDocument
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from credentials.key import key_Mistral, HF_TOKEN
from parametres.params import parent_dir, input_dir, output_dir, exemple_dir, notes_generees_dir, database_dir, RESF_dir, docs_dir, tables_dir, txt_dir

# ============================ Initialisation des cl√©s API ============================
os.environ["HF_TOKEN"] = HF_TOKEN
login(os.environ["HF_TOKEN"])

# ============================ Initialisation des clients ============================
client = Mistral(api_key=key_Mistral)
try:
    model_chat = ChatMistralAI(model="mistral-large-latest", api_key=key_Mistral)
except Exception as e:
    print(f"Erreur lors de l'initialisation du mod√®le Mistral: {e}")
    exit()

# ============================ Mod√®le d'embeddings local ============================
model = AutoModel.from_pretrained("BAAI/bge-m3")
tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-m3")

def get_embeddings(texts):
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        embeddings = model(**inputs).last_hidden_state.mean(dim=1)
    return embeddings

# ============================ Fonctions utilitaires ============================
def invoke_with_retry(model, prompt, max_retries=10):
    retries = 0
    while retries < max_retries:
        try:
            return model.invoke(prompt)
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:
                wait_time = 2 ** retries
                print(f"Rate limit exceeded. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
                retries += 1
            else:
                raise e
    raise Exception("Max retries reached, request failed.")

# ============================ Prompt Template pour Q&A ============================
QA_PROMPT_TEMPLATE = """
En tant qu'expert en analyse de finances publiques, r√©ponds √† la question suivante en te basant uniquement sur le contexte fourni du Rapport √âconomique, Social et Financier (RESF) :

Question : {question}

Contexte du RESF :
{context}

Instructions :
1. R√©ponds de mani√®re pr√©cise et factuelle
2. Cite les chiffres et donn√©es sp√©cifiques du document
3. Utilise un langage professionnel mais accessible
4. Si la r√©ponse n'est pas dans le contexte, indique-le clairement
5. Structure ta r√©ponse de mani√®re claire avec des paragraphes si n√©cessaire
6. R√©ponds en fran√ßais

R√©ponse :
"""
qa_prompt_template = ChatPromptTemplate.from_template(QA_PROMPT_TEMPLATE)

# ============================ D√©finition des chemins ============================
path_input = os.path.join(parent_dir, input_dir)
path_resf = os.path.join(path_input, RESF_dir)
path_output = os.path.join(parent_dir, output_dir)
path_exemple = os.path.join(path_input, exemple_dir)
path_notes_generees = os.path.join(path_output, notes_generees_dir)
path_notes_generees_docs = os.path.join(path_notes_generees, docs_dir)
path_notes_generees_tables = os.path.join(path_notes_generees, tables_dir)
path_notes_generees_txt = os.path.join(path_notes_generees, txt_dir)
path_database = os.path.join(path_output, database_dir)

# Cr√©ation des r√©pertoires
os.makedirs(path_input, exist_ok=True)
os.makedirs(path_output, exist_ok=True)
os.makedirs(path_exemple, exist_ok=True)
os.makedirs(path_notes_generees, exist_ok=True)
os.makedirs(path_notes_generees_docs, exist_ok=True)
os.makedirs(path_notes_generees_tables, exist_ok=True)
os.makedirs(path_database, exist_ok=True)
os.makedirs(path_notes_generees_txt, exist_ok=True)
os.makedirs(path_resf, exist_ok=True)

# ============================ Fonction de traitement OCR ============================
def process_ocr(annee):
    input_file = f"RESF_{annee}.pdf"
    input_path = os.path.join(path_resf, input_file)
    
    if not os.path.exists(input_path):
        print(f"‚ö†Ô∏è Fichier {input_file} non trouv√© dans {input_path}")
        return None

    print(f"üìÑ Traitement du fichier {input_file}...")
    
    try:
        uploaded_pdf = client.files.upload(
            file={
                "file_name": input_path,
                "content": open(input_path, "rb"),
            },
            purpose="ocr"
        )

        signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)

        ocr_response = client.ocr.process(
            model="mistral-ocr-latest",
            document={
                "type": "document_url",
                "document_url": signed_url.url,
            }
        )

        ocr_text_with_pages = ""
        for page_number, page in enumerate(ocr_response.pages, start=1):
            if page.markdown:
                ocr_text_with_pages += f"[{page_number}]\n{page.markdown}\n"

        file_name = f"RESF_{annee}.txt"
        file_path = os.path.join(path_notes_generees_txt, file_name)
        with open(file_path, "w", encoding="utf-8") as file:
            file.write(ocr_text_with_pages)
        
        print(f"‚úÖ OCR termin√© pour {input_file}")
        return file_path
        
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement OCR de {input_file}: {str(e)}")
        return None

# ============================ Fonction de pr√©paration de la base de donn√©es ============================
def prepare_database(annee, input_path, chunk_size=1000, chunk_overlap=50):
    """Pr√©pare la base de donn√©es vectorielle pour une ann√©e donn√©e avec mesure de performance."""
    print(f"üîç Pr√©paration de la base de donn√©es pour RESF {annee}...")
    print(f"üìä Param√®tres : chunk_size={chunk_size}, chunk_overlap={chunk_overlap}")
    
    start_time_total = time.time()
    
    # Lecture du contenu du fichier
    start_time_read = time.time()
    with open(input_path, "r", encoding="utf-8") as f:
        content = f.read()
    read_time = time.time() - start_time_read
    print(f"‚è±Ô∏è Temps de lecture du fichier : {read_time:.2f} secondes")

    document = LangDocument(page_content=content, metadata={"source": input_path, "annee": annee})
    
    # D√©coupage du texte en chunks
    start_time_split = time.time()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = text_splitter.split_documents([document])
    split_time = time.time() - start_time_split
    print(f"‚è±Ô∏è Temps de d√©coupage en chunks : {split_time:.2f} secondes")
    print(f"üìà Nombre de chunks cr√©√©s : {len(chunks)}")
    
    # Cr√©ation de la base de donn√©es vectorielle
    start_time_embedding = time.time()
    chroma_path = os.path.join(path_database, f"db_RESF_{annee}")
    embeddings = MistralAIEmbeddings(model="mistral-embed", api_key=key_Mistral)

    if not os.path.exists(chroma_path):
        db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=chroma_path)
        print(f"‚úÖ Base de donn√©es cr√©√©e pour RESF {annee}")
    else:
        db_chroma = Chroma(persist_directory=chroma_path, embedding_function=embeddings)
        print(f"‚úÖ Base de donn√©es existante charg√©e pour RESF {annee}")
    
    embedding_time = time.time() - start_time_embedding
    total_time = time.time() - start_time_total
    
    print(f"‚è±Ô∏è Temps de cr√©ation/chargement de la base vectorielle : {embedding_time:.2f} secondes")
    print(f"‚è±Ô∏è Temps total de pr√©paration : {total_time:.2f} secondes")
    print(f"üìä R√©sum√© des performances :")
    print(f"   - Lecture : {read_time:.2f}s")
    print(f"   - D√©coupage : {split_time:.2f}s")
    print(f"   - Embeddings : {embedding_time:.2f}s")
    print(f"   - Total : {total_time:.2f}s")
    
    return db_chroma

# ============================ Fonction de test de performance ============================
def test_performance_parameters(annee, input_path):
    """Teste diff√©rentes combinaisons de param√®tres et mesure les performances."""
    print(f"\nüß™ TEST DE PERFORMANCE POUR RESF {annee}")
    print("=" * 60)
    
    # Combinaisons de param√®tres √† tester
    test_configs = [
        {"chunk_size": 500, "chunk_overlap": 25},
        {"chunk_size": 500, "chunk_overlap": 50},
        {"chunk_size": 500, "chunk_overlap": 100},
        {"chunk_size": 500, "chunk_overlap": 150},
        {"chunk_size": 1000, "chunk_overlap": 25},
        {"chunk_size": 1000, "chunk_overlap": 50},
        {"chunk_size": 1000, "chunk_overlap": 100},
        {"chunk_size": 1000, "chunk_overlap": 150},
        {"chunk_size": 1500, "chunk_overlap": 25},
        {"chunk_size": 1500, "chunk_overlap": 50},
        {"chunk_size": 1500, "chunk_overlap": 100},
        {"chunk_size": 1500, "chunk_overlap": 150},
        
    ]
    
    results = []
    
    for i, config in enumerate(test_configs, 1):
        print(f"\nüî¨ Test {i}/{len(test_configs)} : chunk_size={config['chunk_size']}, chunk_overlap={config['chunk_overlap']}")
        print("-" * 50)
        
        start_time = time.time()
        
        # Lecture du contenu
        with open(input_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        document = LangDocument(page_content=content, metadata={"source": input_path, "annee": annee})
        
        # D√©coupage du texte
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config['chunk_size'], 
            chunk_overlap=config['chunk_overlap']
        )
        chunks = text_splitter.split_documents([document])
        
        # Cr√©ation temporaire de la base (sans persistance pour le test)
        embeddings = MistralAIEmbeddings(model="mistral-embed", api_key=key_Mistral)
        db_chroma = Chroma.from_documents(chunks, embeddings)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        result = {
            "chunk_size": config['chunk_size'],
            "chunk_overlap": config['chunk_overlap'],
            "execution_time": execution_time,
            "num_chunks": len(chunks),
            "avg_chunk_size": sum(len(chunk.page_content) for chunk in chunks) / len(chunks) if chunks else 0
        }
        
        results.append(result)
        
        print(f"‚è±Ô∏è Temps d'ex√©cution : {execution_time:.2f} secondes")
        print(f"üìä Nombre de chunks : {len(chunks)}")
        print(f"üìè Taille moyenne des chunks : {result['avg_chunk_size']:.0f} caract√®res")
    
    # Affichage du r√©sum√©
    print(f"\nüìã R√âSUM√â DES PERFORMANCES")
    print("=" * 60)
    print(f"{'Chunk Size':<12} {'Chunk Overlap':<15} {'Temps (s)':<10} {'Chunks':<8} {'Taille moy.':<12}")
    print("-" * 60)
    
    for result in results:
        print(f"{result['chunk_size']:<12} {result['chunk_overlap']:<15} {result['execution_time']:<10.2f} {result['num_chunks']:<8} {result['avg_chunk_size']:<12.0f}")
    
    # Trouver la configuration la plus rapide
    fastest = min(results, key=lambda x: x['execution_time'])
    print(f"\nüèÜ Configuration la plus rapide :")
    print(f"   - Chunk size : {fastest['chunk_size']}")
    print(f"   - Chunk overlap : {fastest['chunk_overlap']}")
    print(f"   - Temps : {fastest['execution_time']:.2f} secondes")
    
    return results

# ============================ Fonction de r√©ponse aux questions ============================
def answer_question(db_chroma, question, annee):
    """R√©pond √† une question en utilisant la base de donn√©es vectorielle."""
    print(f"ü§î Recherche de r√©ponse pour : {question}")
    
    # Recherche des passages pertinents
    docs_chroma = db_chroma.similarity_search_with_score(question, k=5)
    context_text = "\n\n".join([doc.page_content for doc, _score in docs_chroma])

    # G√©n√©ration de la r√©ponse
    prompt = qa_prompt_template.format(question=question, context=context_text)
    response = invoke_with_retry(model_chat, prompt)
    
    return response.content

# ============================ Fonction d'√©valuation de la qualit√© ============================
def evaluate_quality_parameters(annee, input_path, questions):
    """Teste diff√©rentes combinaisons de param√®tres, g√©n√®re les r√©ponses aux questions et exporte dans des fichiers texte."""
    print(f"\nüß™ √âVALUATION DE LA QUALIT√â POUR RESF {annee}")
    print("=" * 60)
    
    # Combinaisons de param√®tres √† tester (m√™mes que test_performance_parameters)
    test_configs = [
        {"chunk_size": 500, "chunk_overlap": 25},
        {"chunk_size": 500, "chunk_overlap": 50},
        {"chunk_size": 500, "chunk_overlap": 100},
        {"chunk_size": 500, "chunk_overlap": 150},
        {"chunk_size": 1000, "chunk_overlap": 25},
        {"chunk_size": 1000, "chunk_overlap": 50},
        {"chunk_size": 1000, "chunk_overlap": 100},
        {"chunk_size": 1000, "chunk_overlap": 150},
        {"chunk_size": 1500, "chunk_overlap": 25},
        {"chunk_size": 1500, "chunk_overlap": 50},
        {"chunk_size": 1500, "chunk_overlap": 100},
        {"chunk_size": 1500, "chunk_overlap": 150},
    ]
    
    for config in test_configs:
        print(f"\nüî¨ G√©n√©ration des r√©ponses pour chunk_size={config['chunk_size']}, chunk_overlap={config['chunk_overlap']}")
        db_chroma = prepare_database(annee, input_path, chunk_size=config['chunk_size'], chunk_overlap=config['chunk_overlap'])
        
        reponses = []
        for idx, question in enumerate(questions, 1):
            print(f"\n‚ùì Question {idx}/{len(questions)} : {question}")
            try:
                reponse = answer_question(db_chroma, question, annee)
            except Exception as e:
                reponse = f"Erreur lors de la g√©n√©ration de la r√©ponse : {e}"
            reponses.append((question, reponse))
        
        # Export dans un fichier texte
        filename = f"reponses_chunk{config['chunk_size']}_overlap{config['chunk_overlap']}.txt"
        filepath = os.path.join(path_notes_generees_txt, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            for idx, (q, r) in enumerate(reponses, 1):
                f.write(f"Question {idx} : {q}\n")
                f.write(f"R√©ponse :\n{r}\n")
                f.write("-"*60 + "\n")
        print(f"‚úÖ R√©ponses export√©es dans {filepath}")

# ============================ Fonction d'affichage du menu ============================
def display_menu():
    """Affiche le menu principal."""
    print("\n" + "="*60)
    print("üìä SYST√àME DE QUESTIONS-R√âPONSES SUR LES RAPPORTS RESF")
    print("="*60)
    print("1. Choisir une ann√©e et poser une question")
    print("2. Voir les ann√©es disponibles")
    print("3. Test de performance des param√®tres")
    print("4. √âvaluer la qualit√© des r√©ponses selon les param√®tres")
    print("5. Quitter")
    print("="*60)

def display_available_years():
    """Affiche les ann√©es disponibles avec leurs statuts."""
    print("\nüìÖ ANN√âES DISPONIBLES :")
    print("-" * 40)
    
    annees = ["2020", "2021", "2022", "2023", "2024", "2025"]
    available_years = []
    
    for annee in annees:
        # V√©rifier si le fichier PDF existe
        pdf_path = os.path.join(path_resf, f"RESF_{annee}.pdf")
        pdf_exists = os.path.exists(pdf_path)
        
        # V√©rifier si la base de donn√©es existe
        db_path = os.path.join(path_database, f"db_RESF_{annee}")
        db_exists = os.path.exists(db_path)
        
        status = ""
        if pdf_exists and db_exists:
            status = "‚úÖ Pr√™t"
            available_years.append(annee)
        elif pdf_exists:
            status = "üìÑ PDF disponible (base √† cr√©er)"
            available_years.append(annee)
        else:
            status = "‚ùå Non disponible"
        
        print(f"RESF {annee} : {status}")
    
    return available_years

# ============================ Fonction de s√©lection d'ann√©e ============================
def select_year(available_years):
    """Permet √† l'utilisateur de s√©lectionner une ann√©e."""
    if not available_years:
        print("‚ùå Aucune ann√©e disponible. Veuillez d'abord traiter les documents PDF.")
        return None
    
    print(f"\nüìã Ann√©es disponibles : {', '.join(available_years)}")
    
    while True:
        try:
            annee = input("\nüéØ Entrez l'ann√©e souhait√©e (ex: 2024) : ").strip()
            if annee in available_years:
                return annee
            else:
                print(f"‚ùå L'ann√©e {annee} n'est pas disponible. Veuillez choisir parmi : {', '.join(available_years)}")
        except KeyboardInterrupt:
            print("\n\nüëã Au revoir !")
            exit()
        except Exception as e:
            print(f"‚ùå Erreur : {e}")

# ============================ Fonction de traitement d'une ann√©e ============================
def process_year(annee):
    """Traite une ann√©e compl√®te (OCR + base de donn√©es)."""
    print(f"\nüîÑ Traitement de l'ann√©e {annee}...")
    
    # √âtape 1: OCR
    input_path = process_ocr(annee)
    if input_path is None:
        return None
        
    # √âtape 2: Pr√©paration de la base de donn√©es
    db_chroma = prepare_database(annee, input_path)
    
    return db_chroma

# ============================ Fonction de session de questions ============================
def question_session(annee, db_chroma):
    """G√®re une session de questions pour une ann√©e donn√©e."""
    print(f"\nüí¨ Session de questions pour RESF {annee}")
    print("üí° Tapez 'quit' pour revenir au menu principal")
    print("üí° Tapez 'help' pour des exemples de questions")
    print("-" * 50)
    
    example_questions = [
        "Quel est le d√©ficit public pr√©vu pour cette ann√©e ?",
        "Quelles sont les principales hypoth√®ses de croissance ?",
        "Comment √©volue la dette publique ?",
        "Quelles sont les principales mesures fiscales ?",
        "Quel est l'impact de la conjoncture √©conomique sur les finances publiques ?"
    ]
    
    while True:
        try:
            question = input(f"\n‚ùì Question sur RESF {annee} : ").strip()
            
            if question.lower() == 'quit':
                print("üëã Retour au menu principal...")
                break
            elif question.lower() == 'help':
                print("\nüìù Exemples de questions que vous pouvez poser :")
                for i, example in enumerate(example_questions, 1):
                    print(f"{i}. {example}")
                continue
            elif not question:
                print("‚ùå Veuillez entrer une question.")
                continue
            
            print("\nüîÑ Recherche en cours...")
            response = answer_question(db_chroma, question, annee)
            
            print(f"\nüìã R√©ponse :")
            print("-" * 40)
            print(response)
            print("-" * 40)
            
        except KeyboardInterrupt:
            print("\n\nüëã Au revoir !")
            exit()
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse : {e}")

# ============================ Programme principal ============================
def main():
    print("üöÄ D√©marrage du syst√®me de Q&A sur les Rapports RESF...")
    
    # Liste des 10 questions √† √©valuer (extraites de l'image)
    questions_eval = [
        "Quelle est la pr√©vision de croissance du PIB pour l'ann√©e 2022 dans le rapport ?",
        "Quelles hypoth√®ses macro√©conomiques sous-tendent la trajectoire du rapport ?",
        "Quelle est l'√©volution attendue de l'inflation en 2022 selon le rapport ?",
        "Quels sont les principaux moteurs de la croissance identifi√©s pour 2022 ?",
        "Comment le rapport √©value-t-il les risques pesant sur la reprise √©conomique ?",
        "Quel est le niveau pr√©vu du d√©ficit public en 2022, en pourcentage du PIB ?",
        "Quelle est la trajectoire de la dette publique pr√©vue dans le rapport ?",
        "Comment √©voluent les d√©penses de l'√âtat en 2022 par rapport √† 2021 ?",
        "Quelles sont les principales mesures nouvelles de politique budg√©taire ?",
        "Quel est le d√©ficit public en 2021 ?"
    ]
    
    while True:
        try:
            display_menu()
            choice = input("\nüéØ Votre choix (1-5) : ").strip()
            
            if choice == "1":
                # Afficher les ann√©es disponibles
                available_years = display_available_years()
                
                # S√©lectionner une ann√©e
                selected_year = select_year(available_years)
                if selected_year is None:
                    continue
                
                # V√©rifier si la base de donn√©es existe
                db_path = os.path.join(path_database, f"db_RESF_{selected_year}")
                if not os.path.exists(db_path):
                    print(f"\nüîÑ La base de donn√©es pour {selected_year} n'existe pas. Cr√©ation en cours...")
                    db_chroma = process_year(selected_year)
                    if db_chroma is None:
                        continue
                else:
                    # Charger la base de donn√©es existante
                    input_path = os.path.join(path_notes_generees_txt, f"RESF_{selected_year}.txt")
                    if os.path.exists(input_path):
                        db_chroma = prepare_database(selected_year, input_path)
                    else:
                        print(f"‚ùå Fichier texte pour {selected_year} non trouv√©. Traitement OCR n√©cessaire...")
                        db_chroma = process_year(selected_year)
                        if db_chroma is None:
                            continue
                
                # D√©marrer la session de questions
                question_session(selected_year, db_chroma)
                
            elif choice == "2":
                display_available_years()
                
            elif choice == "3":
                # Test de performance
                available_years = display_available_years()
                selected_year = select_year(available_years)
                if selected_year is None:
                    continue
                
                # V√©rifier si le fichier texte existe
                input_path = os.path.join(path_notes_generees_txt, f"RESF_{selected_year}.txt")
                if not os.path.exists(input_path):
                    print(f"‚ùå Fichier texte pour {selected_year} non trouv√©. Traitement OCR n√©cessaire...")
                    input_path = process_ocr(selected_year)
                    if input_path is None:
                        continue
                
                # Lancer le test de performance
                test_performance_parameters(selected_year, input_path)
                
            elif choice == "4":
                # √âvaluation de la qualit√©
                available_years = display_available_years()
                selected_year = select_year(available_years)
                if selected_year is None:
                    continue
                input_path = os.path.join(path_notes_generees_txt, f"RESF_{selected_year}.txt")
                if not os.path.exists(input_path):
                    print(f"‚ùå Fichier texte pour {selected_year} non trouv√©. Traitement OCR n√©cessaire...")
                    input_path = process_ocr(selected_year)
                    if input_path is None:
                        continue
                evaluate_quality_parameters(selected_year, input_path, questions_eval)
                
            elif choice == "5":
                print("üëã Au revoir !")
                break
                
            else:
                print("‚ùå Choix invalide. Veuillez entrer 1, 2, 3, 4 ou 5.")
                
        except KeyboardInterrupt:
            print("\n\nüëã Au revoir !")
            break
        except Exception as e:
            print(f"‚ùå Erreur : {e}")

if __name__ == "__main__":
    main()